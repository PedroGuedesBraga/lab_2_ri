{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_2_ri.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "80oO2QCMHsSE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Estatísticas da Coleção e Lei de Zipf **  - Recuperação da Informação\n",
        "Aluno: Pedro Guedes Braga \n"
      ]
    },
    {
      "metadata": {
        "id": "cOXsE-Z0H4rV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "outputId": "f99695b7-c10b-421a-92b5-bf01f38fb272"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import operator\n",
        "import math\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('popular') "
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "metadata": {
        "id": "YD97FGlsJN1U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1 - Reproduza a tabela 4.1 do livro texto calculando as estatísticas para sua coleção (5 pts)."
      ]
    },
    {
      "metadata": {
        "id": "3epHO24zISpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "HK9VKcIE5-BP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "61d24a9c-4b55-4aed-c4b4-d96b1af0e4d8"
      },
      "cell_type": "code",
      "source": [
        "url_csv = \"https://raw.githubusercontent.com/PedroGuedesBraga/ri_lab_01/master/output/results.csv\"\n",
        "df = pd.read_csv(url_csv)\n",
        "df.dropna(inplace=True)  ##Retira campos NA (ex.: NaN, etc)\n",
        "lista_de_noticias = df.text.unique() #Retorna uma lista onde cada elemento é o texto de uma noticia.\n",
        " # http://www.nltk.org/howto/portuguese_en.html - Tutorial StopWords\n",
        " # https://pythonspot.com/tokenizing-words-and-sentences-with-nltk/\n",
        "palavras_a_ignorar = nltk.corpus.stopwords.words('portuguese')\n",
        "  \n",
        "special_chars = [',', '.', '-', '“', \"”\", \")\", \"(\", \":\", \"%\", \"?\", \"$\", \"–\"]\n",
        "\n",
        "def conta_total_palavras(lista_noticias):\n",
        "  total_words = 0\n",
        "  for noticia in lista_noticias:\n",
        "    tokens = word_tokenize(noticia)\n",
        "    for token in tokens:\n",
        "      if((token not in palavras_a_ignorar) and (token not in special_chars)):\n",
        "        total_words += 1\n",
        "  return total_words    \n",
        "  \n",
        "def freq_palavras(lista_noticias):\n",
        "  vocab = {}\n",
        "  for noticia in lista_noticias:\n",
        "    tokens = word_tokenize(noticia)\n",
        "    for token in tokens:\n",
        "      if((token not in palavras_a_ignorar) and (token not in special_chars)):\n",
        "        if(token.lower() in vocab):\n",
        "          vocab[token.lower()] = vocab[token.lower()] + 1\n",
        "        else:\n",
        "          vocab[token.lower()] = 1 \n",
        "  return vocab\n",
        "\n",
        "#Recebe um o numero de vezes e o vocabulario\n",
        "def words_more_than(times, vocab):\n",
        "  count = 0\n",
        "  for word in vocab:\n",
        "    if(vocab[word] > times):\n",
        "      count = count + 1\n",
        "  return count\n",
        "\n",
        "def words_ocurring_once(vocab):\n",
        "  count = 0\n",
        "  for word in vocab:\n",
        "    if(vocab[word] == 1):\n",
        "      count = count + 1\n",
        "  return count\n",
        "\n",
        "\n",
        "vocabulario = freq_palavras(lista_de_noticias)\n",
        "pd.DataFrame({'info': ['Documentos totais',\n",
        "                       'Total de ocorrencias de palavras',\n",
        "                      'Tamanho do Vocabulario',\n",
        "                      'Palavras ocorrendo > 1000 vezes',\n",
        "                       'Palavras ocorrendo uma única vez'\n",
        "                      ],\n",
        "              'valor': [len(df), \n",
        "                        conta_total_palavras(lista_de_noticias),\n",
        "                        len(vocabulario),\n",
        "                        words_more_than(1000, vocabulario),\n",
        "                        words_ocurring_once(vocabulario)\n",
        "                       ]\n",
        "             })"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>info</th>\n",
              "      <th>valor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Documentos totais</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Total de ocorrencias de palavras</td>\n",
              "      <td>42503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tamanho do Vocabulario</td>\n",
              "      <td>12079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Palavras ocorrendo &gt; 1000 vezes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Palavras ocorrendo uma única vez</td>\n",
              "      <td>6966</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               info  valor\n",
              "0                 Documentos totais    139\n",
              "1  Total de ocorrencias de palavras  42503\n",
              "2            Tamanho do Vocabulario  12079\n",
              "3   Palavras ocorrendo > 1000 vezes      0\n",
              "4  Palavras ocorrendo uma única vez   6966"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "metadata": {
        "id": "D5_Li7aJvLrE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2 - Reproduza a tabela 4.2 do livro considerando as top-50 palavras mais frequentes de sua coleção (5 pts). \n"
      ]
    },
    {
      "metadata": {
        "id": "8Np8yqbPxbL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1616
        },
        "outputId": "23ce9cfd-4bac-4633-fc13-38aaa216cbca"
      },
      "cell_type": "code",
      "source": [
        "sorted_d = sorted(vocabulario.items(), key=operator.itemgetter(1), reverse = True)\n",
        "print([y[0] for y in sorted_d][2])\n",
        "total_palavras = conta_total_palavras(lista_de_noticias)\n",
        "freq_relativa = [(v/total_palavras) for (k,v) in sorted_d[:50]]\n",
        "\n",
        "\n",
        "#Calcula o valor da constante 'c' == Pr*r\n",
        "def get_constants_values(freqs_relativas):\n",
        "  constants_values = []\n",
        "  for i in range(len(freqs_relativas)):\n",
        "    c_value = freqs_relativas[i] * (i+1)\n",
        "    constants_values.append(c_value)\n",
        "  return constants_values\n",
        "\n",
        "\n",
        "pd.DataFrame({\n",
        "    'word': [k for (k,v) in sorted_d[:50]],\n",
        "    'freq': [v for (k,v) in sorted_d[:50]],\n",
        "    'Pr(%)': [round((v/total_palavras)*100, 2) for (k,v) in sorted_d[:50]],\n",
        "    'Pr.r': get_constants_values(freq_relativa)\n",
        "    \n",
        "})"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>freq</th>\n",
              "      <th>Pr(%)</th>\n",
              "      <th>Pr.r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>é</td>\n",
              "      <td>728</td>\n",
              "      <td>1.71</td>\n",
              "      <td>0.017128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>o</td>\n",
              "      <td>348</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.016375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>311</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.021951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ser</td>\n",
              "      <td>179</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.016846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>brasil</td>\n",
              "      <td>175</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.020587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bolsonaro</td>\n",
              "      <td>172</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.024281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>anos</td>\n",
              "      <td>172</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.028327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>governo</td>\n",
              "      <td>170</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.031998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sobre</td>\n",
              "      <td>129</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.027316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>presidente</td>\n",
              "      <td>127</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.029880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>país</td>\n",
              "      <td>114</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.029504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>lula</td>\n",
              "      <td>111</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.031339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>política</td>\n",
              "      <td>106</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.032421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>porque</td>\n",
              "      <td>99</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.032609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>pode</td>\n",
              "      <td>99</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.034939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>não</td>\n",
              "      <td>97</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.036515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>gente</td>\n",
              "      <td>96</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.038397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ainda</td>\n",
              "      <td>90</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.038115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ter</td>\n",
              "      <td>88</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.039338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>pessoas</td>\n",
              "      <td>87</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.040938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>hoje</td>\n",
              "      <td>86</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.042491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>em</td>\n",
              "      <td>81</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.041926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>nacional</td>\n",
              "      <td>81</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.043832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>reforma</td>\n",
              "      <td>80</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.045173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>eu</td>\n",
              "      <td>76</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.044703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>educação</td>\n",
              "      <td>75</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.045879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>contra</td>\n",
              "      <td>75</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.047644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>e</td>\n",
              "      <td>72</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.047432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>vai</td>\n",
              "      <td>72</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.049126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>segundo</td>\n",
              "      <td>71</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.050114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>no</td>\n",
              "      <td>70</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.051055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>fazer</td>\n",
              "      <td>68</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.051196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>disse</td>\n",
              "      <td>67</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.052020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>apenas</td>\n",
              "      <td>67</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.053596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>justiça</td>\n",
              "      <td>66</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.054349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>os</td>\n",
              "      <td>65</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.055055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>dia</td>\n",
              "      <td>65</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.056584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>mas</td>\n",
              "      <td>65</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.058114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>trabalho</td>\n",
              "      <td>64</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.058725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>federal</td>\n",
              "      <td>64</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.060231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>na</td>\n",
              "      <td>63</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.060772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>direitos</td>\n",
              "      <td>63</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.062254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>lei</td>\n",
              "      <td>62</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.062725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>menos</td>\n",
              "      <td>61</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.063148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>caso</td>\n",
              "      <td>61</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.064584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>ditadura</td>\n",
              "      <td>60</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.064937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>então</td>\n",
              "      <td>58</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.064137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>jair</td>\n",
              "      <td>58</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.065501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>são</td>\n",
              "      <td>58</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.066866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>ano</td>\n",
              "      <td>58</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.068230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          word  freq  Pr(%)      Pr.r\n",
              "0            é   728   1.71  0.017128\n",
              "1            o   348   0.82  0.016375\n",
              "2            a   311   0.73  0.021951\n",
              "3          ser   179   0.42  0.016846\n",
              "4       brasil   175   0.41  0.020587\n",
              "5    bolsonaro   172   0.40  0.024281\n",
              "6         anos   172   0.40  0.028327\n",
              "7      governo   170   0.40  0.031998\n",
              "8        sobre   129   0.30  0.027316\n",
              "9   presidente   127   0.30  0.029880\n",
              "10        país   114   0.27  0.029504\n",
              "11        lula   111   0.26  0.031339\n",
              "12    política   106   0.25  0.032421\n",
              "13      porque    99   0.23  0.032609\n",
              "14        pode    99   0.23  0.034939\n",
              "15         não    97   0.23  0.036515\n",
              "16       gente    96   0.23  0.038397\n",
              "17       ainda    90   0.21  0.038115\n",
              "18         ter    88   0.21  0.039338\n",
              "19     pessoas    87   0.20  0.040938\n",
              "20        hoje    86   0.20  0.042491\n",
              "21          em    81   0.19  0.041926\n",
              "22    nacional    81   0.19  0.043832\n",
              "23     reforma    80   0.19  0.045173\n",
              "24          eu    76   0.18  0.044703\n",
              "25    educação    75   0.18  0.045879\n",
              "26      contra    75   0.18  0.047644\n",
              "27           e    72   0.17  0.047432\n",
              "28         vai    72   0.17  0.049126\n",
              "29     segundo    71   0.17  0.050114\n",
              "30          no    70   0.16  0.051055\n",
              "31       fazer    68   0.16  0.051196\n",
              "32       disse    67   0.16  0.052020\n",
              "33      apenas    67   0.16  0.053596\n",
              "34     justiça    66   0.16  0.054349\n",
              "35          os    65   0.15  0.055055\n",
              "36         dia    65   0.15  0.056584\n",
              "37         mas    65   0.15  0.058114\n",
              "38    trabalho    64   0.15  0.058725\n",
              "39     federal    64   0.15  0.060231\n",
              "40          na    63   0.15  0.060772\n",
              "41    direitos    63   0.15  0.062254\n",
              "42         lei    62   0.15  0.062725\n",
              "43       menos    61   0.14  0.063148\n",
              "44        caso    61   0.14  0.064584\n",
              "45    ditadura    60   0.14  0.064937\n",
              "46       então    58   0.14  0.064137\n",
              "47        jair    58   0.14  0.065501\n",
              "48         são    58   0.14  0.066866\n",
              "49         ano    58   0.14  0.068230"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    }
  ]
}